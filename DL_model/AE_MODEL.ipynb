{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_MODEL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKWxb4j0BYTt",
        "colab_type": "code",
        "outputId": "4faa12c1-de8d-4153-caa3-07228b9b4ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (47.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0.post3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKQQZr1BmPxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f21f7ce-bb6f-466e-9248-9b7049d89ae8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "print(tf.__version__)\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import pdb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhCrfEULa51m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_folder = Path('INSERT YOUR PATH HERE')\n",
        "data_folder = Path('/content/drive/My Drive/Mary Jane Inc./Data')\n",
        "player_data = data_folder / 'Player Stats'\n",
        "team_data = data_folder / 'Team Stats'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btw0TOqDl7dl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7780424-e74a-4a6e-b988-ce26fd8b751a"
      },
      "source": [
        "years = ['09','10','11','12','13','14','15','16','17','18','19']\n",
        "for i in tqdm(range(len(years) - 1)):\n",
        "  if i == 0:\n",
        "    df_p = pd.read_excel(player_data / f'NBA-20{years[i]}-20{years[i + 1]}-Player-BoxScore-Dataset.xlsx',sheet_name=f'NBA-20{years[i]}-{years[i + 1]}-PLAYER')\n",
        "    df_t = pd.read_excel(team_data / f'20{years[i]}-20{years[i + 1]}_NBA_Box_Score_Team-Stats.xlsx',sheet_name=f'NBA-20{years[i]}-{years[i + 1]}-TEAM')\n",
        "  else:\n",
        "    temp_p = pd.read_excel(player_data / f'NBA-20{years[i]}-20{years[i + 1]}-Player-BoxScore-Dataset.xlsx',sheet_name=f'NBA-20{years[i]}-{years[i + 1]}-PLAYER')\n",
        "    temp_t = pd.read_excel(team_data / f'20{years[i]}-20{years[i + 1]}_NBA_Box_Score_Team-Stats.xlsx',sheet_name=f'NBA-20{years[i]}-{years[i + 1]}-TEAM')\n",
        "    df_p = df_p.append(temp_p)\n",
        "    df_t = df_t.append(temp_t)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:10<00:00,  7.06s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9varYnR5ogBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process_player(player_frame):\n",
        "  player_frame = player_frame.drop(['DATASET', 'PLAYER \\nFULL NAME', 'OWN \\nTEAM', 'OPPONENT \\nTEAM'],axis=1)\n",
        "  player_frame = player_frame.rename(columns={'VENUE\\n(R/H)':'VENUE','STARTER\\n(Y/N)':'STARTER','USAGE \\nRATE (%)':'USAGE','DAYS\\nREST':'REST','GAME-ID':'G_ID','PLAYER-ID':'P_ID'})\n",
        "  starter_int = {start:int(i) for i, start in enumerate(['Y', 'N'])}\n",
        "  venue_int = {ven:int(i) for i, ven in enumerate(['H','R'])}\n",
        "  position_int = {pos:int(i) for i, pos in enumerate(['F', 'C', 'G', 'C-F', 'G-F', 'F-G', 'F-C', 'SF', 'PF', 'PG', 'SG', 'OTHER'])}\n",
        "  rest_int = {'3+':int(666)}\n",
        "  player_frame = player_frame.replace({'STARTER':starter_int,'VENUE':venue_int,'POSITION':position_int,'REST':rest_int})\n",
        "  player_frame['POSITION'] = player_frame['POSITION'].fillna(11.0)\n",
        "  player_frame['POSITION'] = player_frame['POSITION'].astype('int64')\n",
        "  player_frame['REST'] = player_frame['REST'].astype('int64')\n",
        "  player_frame['DATE'] = pd.to_datetime(player_frame['DATE'],format='%m/%d/%Y')\n",
        "  return player_frame\n",
        "df_p = pre_process_player(df_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d50BvjNetZdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_p.columns\n",
        "df_p = df_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-nL7o5EsVke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "efbd66c6-df04-480a-b24c-939b757b8f97"
      },
      "source": [
        "num_game_history = 3\n",
        "cols = ['G_ID', 'DATE', 'P_ID', 'POSITION', 'VENUE', 'STARTER', 'MIN', 'FG', 'FGA', '3P', '3PA', 'FT', 'FTA', 'OR', 'DR', 'TOT', 'A', 'PF', 'ST', 'TO', 'BL', 'PTS', 'USAGE', 'REST',  'g1_G_ID', 'g1_DATE', 'g1_P_ID', 'g1_POSITION', 'g1_VENUE', 'g1_STARTER', 'g1_MIN', 'g1_FG', 'g1_FGA', 'g1_3P', 'g1_3PA', 'g1_FT', 'g1_FTA', 'g1_OR', 'g1_DR', 'g1_TOT', 'g1_A', 'g1_PF', 'g1_ST', 'g1_TO', 'g1_BL', 'g1_PTS', 'g1_USAGE', 'g1_REST', 'g2_G_ID', 'g2_DATE', 'g2_P_ID', 'g2_POSITION', 'g2_VENUE', 'g2_STARTER', 'g2_MIN', 'g2_FG', 'g2_FGA', 'g2_3P', 'g2_3PA', 'g2_FT', 'g2_FTA', 'g2_OR', 'g2_DR', 'g2_TOT', 'g2_A', 'g2_PF', 'g2_ST', 'g2_TO', 'g2_BL', 'g2_PTS', 'g2_USAGE', 'g2_REST', 'g3_G_ID', 'g3_DATE', 'g3_P_ID', 'g3_POSITION', 'g3_VENUE', 'g3_STARTER', 'g3_MIN', 'g3_FG', 'g3_FGA', 'g3_3P', 'g3_3PA', 'g3_FT', 'g3_FTA', 'g3_OR', 'g3_DR', 'g3_TOT', 'g3_A', 'g3_PF', 'g3_ST', 'g3_TO', 'g3_BL', 'g3_PTS', 'g3_USAGE', 'g3_REST']\n",
        "dataset = []\n",
        "for id in tqdm(df_p['P_ID'].unique()):\n",
        "  dis_person = df_p[df_p['P_ID'] == id]\n",
        "  for index, row in dis_person.iterrows():\n",
        "    prev_games = dis_person[dis_person['DATE'] <= row['DATE']].sort_values('DATE',ascending=False)\n",
        "    # prev_games = prev_games.drop(columns=['G_ID','P_ID'])\n",
        "    if len(prev_games) >= num_game_history + 1:\n",
        "      prev_games = prev_games.nlargest(num_game_history + 1, 'DATE').values.flatten()\n",
        "      dataset.append(prev_games)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1238 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/1238 [00:02<45:12,  2.19s/it]\u001b[A\n",
            "  0%|          | 2/1238 [00:03<41:41,  2.02s/it]\u001b[A\n",
            "  0%|          | 3/1238 [00:05<40:52,  1.99s/it]\u001b[A\n",
            "  0%|          | 4/1238 [00:07<38:59,  1.90s/it]\u001b[A\n",
            "  0%|          | 5/1238 [00:09<42:30,  2.07s/it]\u001b[A\n",
            "  0%|          | 6/1238 [00:10<32:49,  1.60s/it]\u001b[A\n",
            "  1%|          | 7/1238 [00:11<28:06,  1.37s/it]\u001b[A\n",
            "  1%|          | 8/1238 [00:11<23:46,  1.16s/it]\u001b[A\n",
            "  1%|          | 9/1238 [00:12<19:43,  1.04it/s]\u001b[A\n",
            "  1%|          | 10/1238 [00:15<34:27,  1.68s/it]\u001b[A\n",
            "  1%|          | 11/1238 [00:16<31:22,  1.53s/it]\u001b[A\n",
            "  1%|          | 12/1238 [00:17<24:14,  1.19s/it]\u001b[A\n",
            "  1%|          | 13/1238 [00:18<21:30,  1.05s/it]\u001b[A\n",
            "  1%|          | 14/1238 [00:19<25:17,  1.24s/it]\u001b[A\n",
            "  1%|          | 15/1238 [00:20<21:09,  1.04s/it]\u001b[A\n",
            "  1%|▏         | 16/1238 [00:21<19:43,  1.03it/s]\u001b[A\n",
            "  1%|▏         | 17/1238 [00:22<24:37,  1.21s/it]\u001b[A\n",
            "  1%|▏         | 18/1238 [00:23<20:29,  1.01s/it]\u001b[A\n",
            "  2%|▏         | 19/1238 [00:25<24:19,  1.20s/it]\u001b[A\n",
            "  2%|▏         | 20/1238 [00:25<18:26,  1.10it/s]\u001b[A\n",
            "  2%|▏         | 21/1238 [00:26<20:08,  1.01it/s]\u001b[A\n",
            "  2%|▏         | 22/1238 [00:28<24:46,  1.22s/it]\u001b[A\n",
            "  2%|▏         | 23/1238 [00:28<20:09,  1.00it/s]\u001b[A\n",
            "  2%|▏         | 24/1238 [00:29<21:25,  1.06s/it]\u001b[A\n",
            "  2%|▏         | 25/1238 [00:30<20:56,  1.04s/it]\u001b[A\n",
            "  2%|▏         | 26/1238 [00:31<18:48,  1.07it/s]\u001b[A\n",
            "  2%|▏         | 27/1238 [00:33<26:03,  1.29s/it]\u001b[A\n",
            "  2%|▏         | 28/1238 [00:35<31:46,  1.58s/it]\u001b[A\n",
            "  2%|▏         | 29/1238 [00:37<33:06,  1.64s/it]\u001b[A\n",
            "  2%|▏         | 30/1238 [00:40<40:01,  1.99s/it]\u001b[A\n",
            "  3%|▎         | 31/1238 [00:41<30:56,  1.54s/it]\u001b[A\n",
            "  3%|▎         | 32/1238 [00:41<23:44,  1.18s/it]\u001b[A\n",
            "  3%|▎         | 33/1238 [00:42<24:25,  1.22s/it]\u001b[A\n",
            "  3%|▎         | 34/1238 [00:45<33:57,  1.69s/it]\u001b[A\n",
            "  3%|▎         | 35/1238 [00:46<30:53,  1.54s/it]\u001b[A\n",
            "  3%|▎         | 36/1238 [00:49<37:48,  1.89s/it]\u001b[A\n",
            "  3%|▎         | 37/1238 [00:51<38:24,  1.92s/it]\u001b[A\n",
            "  3%|▎         | 38/1238 [00:52<36:39,  1.83s/it]\u001b[A\n",
            "  3%|▎         | 39/1238 [00:55<39:31,  1.98s/it]\u001b[A\n",
            "  3%|▎         | 40/1238 [00:56<36:31,  1.83s/it]\u001b[A\n",
            "  3%|▎         | 41/1238 [00:59<43:09,  2.16s/it]\u001b[A\n",
            "  3%|▎         | 42/1238 [01:01<42:32,  2.13s/it]\u001b[A\n",
            "  3%|▎         | 43/1238 [01:04<46:11,  2.32s/it]\u001b[A\n",
            "  4%|▎         | 44/1238 [01:06<41:23,  2.08s/it]\u001b[A\n",
            "  4%|▎         | 45/1238 [01:06<31:13,  1.57s/it]\u001b[A\n",
            "  4%|▎         | 46/1238 [01:06<22:25,  1.13s/it]\u001b[A\n",
            "  4%|▍         | 47/1238 [01:08<24:45,  1.25s/it]\u001b[A\n",
            "  4%|▍         | 48/1238 [01:09<25:08,  1.27s/it]\u001b[A\n",
            "  4%|▍         | 49/1238 [01:12<33:37,  1.70s/it]\u001b[A\n",
            "  4%|▍         | 50/1238 [01:12<24:27,  1.24s/it]\u001b[A\n",
            "  4%|▍         | 51/1238 [01:12<19:40,  1.01it/s]\u001b[A\n",
            "  4%|▍         | 52/1238 [01:14<23:43,  1.20s/it]\u001b[A\n",
            "  4%|▍         | 53/1238 [01:15<21:42,  1.10s/it]\u001b[A\n",
            "  4%|▍         | 54/1238 [01:17<26:01,  1.32s/it]\u001b[A\n",
            "  4%|▍         | 55/1238 [01:17<21:56,  1.11s/it]\u001b[A\n",
            "  5%|▍         | 56/1238 [01:18<17:38,  1.12it/s]\u001b[A\n",
            "  5%|▍         | 57/1238 [01:18<15:23,  1.28it/s]\u001b[A\n",
            "  5%|▍         | 58/1238 [01:19<15:43,  1.25it/s]\u001b[A\n",
            "  5%|▍         | 59/1238 [01:20<18:31,  1.06it/s]\u001b[A\n",
            "  5%|▍         | 60/1238 [01:22<25:43,  1.31s/it]\u001b[A\n",
            "  5%|▍         | 61/1238 [01:23<21:38,  1.10s/it]\u001b[A\n",
            "  5%|▌         | 62/1238 [01:24<22:29,  1.15s/it]\u001b[A\n",
            "  5%|▌         | 63/1238 [01:24<16:33,  1.18it/s]\u001b[A\n",
            "  5%|▌         | 64/1238 [01:25<15:20,  1.28it/s]\u001b[A\n",
            "  5%|▌         | 65/1238 [01:26<15:20,  1.27it/s]\u001b[A\n",
            "  5%|▌         | 66/1238 [01:29<28:25,  1.45s/it]\u001b[A\n",
            "  5%|▌         | 67/1238 [01:30<28:20,  1.45s/it]\u001b[A\n",
            "  5%|▌         | 68/1238 [01:31<26:27,  1.36s/it]\u001b[A\n",
            "  6%|▌         | 69/1238 [01:32<23:30,  1.21s/it]\u001b[A\n",
            "  6%|▌         | 70/1238 [01:34<25:05,  1.29s/it]\u001b[A\n",
            "  6%|▌         | 71/1238 [01:35<26:26,  1.36s/it]\u001b[A\n",
            "  6%|▌         | 72/1238 [01:36<24:58,  1.29s/it]\u001b[A\n",
            "  6%|▌         | 73/1238 [01:37<22:40,  1.17s/it]\u001b[A\n",
            "  6%|▌         | 74/1238 [01:38<17:46,  1.09it/s]\u001b[A\n",
            "  6%|▌         | 75/1238 [01:39<19:24,  1.00s/it]\u001b[A\n",
            "  6%|▌         | 76/1238 [01:39<16:23,  1.18it/s]\u001b[A\n",
            "  6%|▌         | 77/1238 [01:40<15:02,  1.29it/s]\u001b[A\n",
            "  6%|▋         | 78/1238 [01:41<16:33,  1.17it/s]\u001b[A\n",
            "  6%|▋         | 79/1238 [01:42<15:11,  1.27it/s]\u001b[A\n",
            "  6%|▋         | 80/1238 [01:44<23:43,  1.23s/it]\u001b[A\n",
            "  7%|▋         | 81/1238 [01:45<25:15,  1.31s/it]\u001b[A\n",
            "  7%|▋         | 82/1238 [01:46<19:40,  1.02s/it]\u001b[A\n",
            "  7%|▋         | 83/1238 [01:46<15:34,  1.24it/s]\u001b[A\n",
            "  7%|▋         | 84/1238 [01:47<16:32,  1.16it/s]\u001b[A\n",
            "  7%|▋         | 85/1238 [01:48<18:33,  1.04it/s]\u001b[A\n",
            "  7%|▋         | 86/1238 [01:49<15:35,  1.23it/s]\u001b[A\n",
            "  7%|▋         | 87/1238 [01:49<12:33,  1.53it/s]\u001b[A\n",
            "  7%|▋         | 88/1238 [01:52<24:32,  1.28s/it]\u001b[A\n",
            "  7%|▋         | 89/1238 [01:54<29:12,  1.52s/it]\u001b[A\n",
            "  7%|▋         | 90/1238 [01:57<36:34,  1.91s/it]\u001b[A\n",
            "  7%|▋         | 91/1238 [01:59<40:14,  2.10s/it]\u001b[A\n",
            "  7%|▋         | 92/1238 [02:00<33:15,  1.74s/it]\u001b[A\n",
            "  8%|▊         | 93/1238 [02:03<40:02,  2.10s/it]\u001b[A\n",
            "  8%|▊         | 94/1238 [02:06<43:18,  2.27s/it]\u001b[A\n",
            "  8%|▊         | 95/1238 [02:06<33:58,  1.78s/it]\u001b[A\n",
            "  8%|▊         | 96/1238 [02:09<39:02,  2.05s/it]\u001b[A\n",
            "  8%|▊         | 97/1238 [02:09<29:03,  1.53s/it]\u001b[A\n",
            "  8%|▊         | 98/1238 [02:12<36:25,  1.92s/it]\u001b[A\n",
            "  8%|▊         | 99/1238 [02:14<34:06,  1.80s/it]\u001b[A\n",
            "  8%|▊         | 100/1238 [02:15<31:23,  1.65s/it]\u001b[A\n",
            "  8%|▊         | 101/1238 [02:18<38:17,  2.02s/it]\u001b[A\n",
            "  8%|▊         | 102/1238 [02:20<41:00,  2.17s/it]\u001b[A\n",
            "  8%|▊         | 103/1238 [02:23<41:30,  2.19s/it]\u001b[A\n",
            "  8%|▊         | 104/1238 [02:23<30:51,  1.63s/it]\u001b[A\n",
            "  8%|▊         | 105/1238 [02:25<32:23,  1.72s/it]\u001b[A\n",
            "  9%|▊         | 106/1238 [02:25<24:45,  1.31s/it]\u001b[A\n",
            "  9%|▊         | 107/1238 [02:27<25:05,  1.33s/it]\u001b[A\n",
            "  9%|▊         | 108/1238 [02:27<20:44,  1.10s/it]\u001b[A\n",
            "  9%|▉         | 109/1238 [02:28<18:53,  1.00s/it]\u001b[A\n",
            "  9%|▉         | 110/1238 [02:30<25:22,  1.35s/it]\u001b[A\n",
            "  9%|▉         | 111/1238 [02:32<31:17,  1.67s/it]\u001b[A\n",
            "  9%|▉         | 112/1238 [02:35<36:37,  1.95s/it]\u001b[A\n",
            "  9%|▉         | 113/1238 [02:37<36:36,  1.95s/it]\u001b[A\n",
            "  9%|▉         | 114/1238 [02:39<37:08,  1.98s/it]\u001b[A\n",
            "  9%|▉         | 115/1238 [02:39<28:24,  1.52s/it]\u001b[A\n",
            "  9%|▉         | 116/1238 [02:42<35:07,  1.88s/it]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBh9fuqq_iim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "final_dataset = np.array(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPHBqEDpawel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
        "\n",
        "  def __init__(self, latent_dim):\n",
        "    super(CVAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            # No activation\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    self.decoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            # No activation\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  @tf.function\n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csSKS5C0bfv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis=raxis)\n",
        "\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "  \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "  This function computes the loss and gradients, and uses the latter to\n",
        "  update the model's parameters.\n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLXSFcutNs1g",
        "colab_type": "code",
        "outputId": "a8fcc257-c317-4913-a0af-5335493fc928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "testing = df_p.drop(columns=['DATASET', 'PLAYER \\nFULL NAME', 'OWN \\nTEAM', 'OPPONENT \\nTEAM'])\n",
        "testing = testing.rename(columns={'VENUE\\n(R/H)':'VENUE','STARTER\\n(Y/N)':'STARTER','USAGE \\nRATE (%)':'USAGE', 'DAYS\\nREST':'REST'})\n",
        "starter_map = {i: start for i, start in enumerate(['Y', 'N'])}\n",
        "venue_map = {i: ven for i, ven in enumerate(['R', 'H'])}\n",
        "position_map = {i: pos for i, pos in enumerate(['F', 'C', 'G', 'C-F', 'G-F', 'F-G', 'F-C', 'SF', 'PF', 'PG', 'SG'])}\n",
        "testing = testing.replace({'STARTER':starter_map, 'VENUE':venue_map,'POSITION':position_map})\n",
        "testing = testing['POSITION'].fillna(666)\n",
        "pdb.set_trace()\n",
        "testing['DATE'] = pd.to_datetime(testing['DATE'],format='%m/%d/%Y')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-012ab3a6b187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHuraqK7Nt6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}